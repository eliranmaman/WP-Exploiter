import xmltodict
import urllib.parse as urlparse
from urllib.parse import parse_qs
from http_handler.request_handler import HTTPHandler
from wordpress.wplogs import WPLogs


_ADMIN_PATH = "/wp-admin"
_LOGIN_PATH = "wp-login.php"
_FEED_PATH = "/feed"
_UPGRADE_PATH = _ADMIN_PATH + "/upgrade.php"
_TIMEOUT = 5
_CSS_PATH = ["/style-rtl.min.css?ver=", "/style.min.css?ver=", "/wp-emoji-release.min.js?ver=",
                    "/install.min.css?ver=", "buttons.min.css?ver=", "<meta name=\"generator\" content=\"WordPress"]
_DETECT_TH = 0.4


def clean_url(url):
    if url[-1:] is "/":
        url = url[:-1]
    return url

class WPDetector:

    def __init__(self, domain, proxies=None, timeout=_TIMEOUT):
        self._http_handler = HTTPHandler()
        self._proxies = proxies
        self._words_values = {"/wp-content/": 0.8, '<meta name="generator" content="WordPress': 0.8,
                              "/wordpress/": 0.8, "WordPress": 0.2, "wp-emoji-release.min.js": 0.8}
        self._files_needles = {"license.txt": "WordPress - Web publishing software",
                               "readme.html": "Semantic Personal Publishing Platform"}
        self._web_data = dict()
        self._url = clean_url(str(domain))
        self._is_wp = False
        self._timeout = timeout
        self._logs = WPLogs()

    def __check_admin_panel(self, url):
        response = self.__get_page_data(url)
        if response is not None and _LOGIN_PATH in str(response.url):
            return 1
        return 0  # not a wardress site

    def __check_words(self, url):
        probability = 0
        response = self.__get_page_data(url)
        if response is None:
            return None
        content = str(response.content)
        if content is not None:
            for word, value in self._words_values.items():
                if word in content:
                    probability += value
            return probability
        return None

    def __check_files(self, url):
        counter = 0
        for file, needle in self._files_needles.items():
            assembled_url = url + '/' + file
            response = self.__get_page_data(assembled_url)
            if response is None:
                return 0
            content = str(response.content)
            if needle in content:
                counter += 1

        return counter/len(self._files_needles.keys())

    def get_version(self, url, timeout=_TIMEOUT):
        self._timeout = timeout
        url = str(url)
        version = None
        try:
            url = clean_url(url)
        except Exception as e:
            print("Error: while cleaning the url at get_version function.")
            self._logs.save_log(e, "Error: while cleaning the url at get_version function.")
        # try the first method to detect the version
        try:
            version = self.__find_version_in_source(url)
        except Exception as e:
            msg = "Error: __find_version_in_source function invoke from get_version is failed."
            print(msg)
            self._logs.save_log(e, msg)
        if version is not None:
            return version
        # try the 2nd method to detect the version
        try:
            version = self.__find_version_in_feed(url + _FEED_PATH)
        except Exception as e:
            msg = "Error: __find_version_in_feed function invoke from get_version is failed."
            print(msg)
            self._logs.save_log(e, msg)
        if version is not None:
            return version
        # try the 3rd method to detect the version
        try:
            version = self.__find_version_in_source(url + _UPGRADE_PATH)
        except Exception as e:
            msg = "Error: __find_version_in_source(_UPGRADE_PATH) function invoke from get_version is failed."
            print(msg)
            self._logs.save_log(e, msg)
        if version is None:
            version = "Unknown"
        return version

    def __find_version_in_feed(self, url):
        response = None
        try:
            response = self.__get_page_data(url)  # get page data from cache (or invoke new request)
            if response is None:
                return None
            response = response.content
            if response is None:
                return None
        except Exception as e:
            msg = "Error: cannot get page date - "+url
            print(msg)
            self._logs.save_log(e, msg)
            return None
        try:
            page = xmltodict.parse(response)  # page => to xml
            ver_url = page["rss"]["channel"]["generator"]  # get the generator var
            ver_url = urlparse.urlparse(ver_url)  # extract the v parameter
            version = parse_qs(ver_url.query)['v'][0]
            return version
        except Exception as e:
            msg = "Error: xml to dict is failed for " + url
            self._logs.save_log(e, msg)
            return None

    def __find_version_in_source(self, url):
        version = None
        response = self.__get_page_data(url)
        if response is None:
            return None
        data = str(response.content)
        for css_item in _CSS_PATH:  # foreach item in the _CSS_PATH do
            version = data.partition(css_item)[2].partition("\"")[0]
            if len(version) > 10:  # if the len is bigger then 10 its need another parse
                version = version.split("\\")[0].split("\'")[0]
            elif len(version) > 1:  # we got the version number.
                return version
            else:
                version = None  # no version found.
        return version

    def __check_if_wp(self, url):
        words_prob = 0
        try:
            words_prob = self.__check_words(url)
            if words_prob is None:
                return None
        except Exception as e:
            msg = "Error: __check_if_wp =>  __check_words invoke failed for: " + url
            self._logs.save_log(e, msg)
            return None
        files_prob = 0
        try:
            files_prob = self.__check_files(url)
        except Exception as e:
            msg = "Error: __check_if_wp =>  __check_files invoke failed for: " + url
            self._logs.save_log(e, msg)
        return (words_prob+files_prob)/2

    def detect(self, url, threshold=_DETECT_TH, timeout=_TIMEOUT):
        self._timeout = timeout
        try:
            if self.__check_admin_panel(url) is True:  # if found WP admin panel => is WP!
                return True
        except Exception as e:
            msg = "Error: detect =>  __check_admin_panel invoke failed for: " + url
            self._logs.save_log(e, msg)
        try:
            prob = self.__check_if_wp(url)
            if prob is None:
                return False
        except Exception as e:
            msg = "Error: could not load page"
            print(msg)
            self._logs.save_log(e, msg)
            return False
        if prob >= threshold:
            return True
        else:
            return False

    def __get_page_data(self, url):
        #  this function is responsible for requests cache.
        response = self._web_data.get(url, None)
        if response is None:
            response = self._http_handler.request(url=url, method="GET", timeout=self._timeout, proxies=self._proxies)
            self._web_data[url] = response
        return response

